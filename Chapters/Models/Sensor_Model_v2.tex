% \begin{equation}
%     \boxed{ \color{blue}    \color{black}}
% \end{equation}

%-----------------------------------------------------------%

% -------- %
% Overview %
% -------- %

\subsubsection{Overview} % Summary
The version 2 Model for \SIS involves ideal optics, with the Sensor Model with major sensor noises. A modest flowchart of the Sensor Model is as follows:

\begin{Flowchart}[h!]
    \centering
    \includegraphics[scale=0.09]{Figures/Model/Sensor Model v2.png}
    \caption{Star Image Simulation Flowchart - Version 2}
    \label{fig:SIS_v2}
\end{Flowchart}

% ------ %
% Inputs %
% ------ %

\subsubsection{Inputs}
The inputs to the \SISM are as follows:
\begin{enumerate}[label={}]
    \descitem{Star Catalogue -} This is the SSP Star Catalogue, which is pre-processed for \SIS. The SSP Star Catalogue has been generated from the SKY 2000 Catalogue. 
    \descitem{Boresight Inputs -} This includes the Boresight data, or the Attitude data at instants when images are to be generated. This is currently manually created, however, in the future, this is the ouput of the Dynamics Block.
    \descitem{Sensor Model Inputs -} This includes global inputs to the \SISM, which includes parameters like Star Magnitude Limit for \SISM and the Number of Boresight Inputs. 
    \descitem{Optics Inputs -} This includes parameter inputs from Optics Perspective, i.e. relates to the Lens System and the CMOS Sensor.
    \descitem{Image Generation Inputs -} This includes parameters related to Image Generation at the CMOS Sensor taken from the data-sheet for PYTHON-1300.
    \descitem{Error Inputs -} This includes all the parameters required to model the Sensor Noise. These have been taken from the data-sheet for PYTHON-1300.
\end{enumerate}

% -------------- %
% Pre-Processing %
% -------------- %

\subsubsection{Pre-processing} % 2 parts - Loading constants, and Pre-processing of Catalogue
The pre-processing sub-block involves 2 steps -
\begin{enumerate}[label={}]
    \descitem{Loading Inputs and Calculating Parameters -} This sub-sub-block involves loading all the inputs from the .xlsx files, and calculations of parameters from the inputs, where the inputs are converted into SI units for uniformity and dependent parameters are calculated from the independent parameters. 
    \descitem{Pre-processing Catalogue -} The SSP Star Catalogue is pre-processed to include parameters which are used multiple times in the \SIS. These include the calculation of the Unit Vectors in the ICRS Frame from the Right Ascension, Declination values given in the SSP Star Catalogue. Unnecessary columns are also removed in this step. 
\end{enumerate}

A modest flowchart for the Pre-processing sub-block is given here -

\begin{Flowchart}[h!]
    \centering
    \includegraphics[scale=0.09]{Figures/Model/Pre-processing.png}
    \caption{Pre-Processing Sub-Block - Version 2}
    \label{fig:SIS_v2_PP}
\end{Flowchart}

% ---------- %
% Processing %
% ---------- %

\subsubsection{Processing}

The flowchart for the Processing sub-block is given in Figure \ref{fig:SIS_v2_PR}

\begin{Flowchart}[h!]
    \centering
    \includegraphics[scale=0.09]{Figures/Model/Processing.png}
    \caption{Processing Sub-Block - Version 2}
    \label{fig:SIS_v2_PR}
\end{Flowchart}

Visual information is recorded via the CMOS sensor placed at the focal plane of the optics system to measure the light gathered during the exposure. The sensor is platted into an array of pixels, each of which is tasked to gather the light arriving within a small patch of sensor area. The efficiency with which the sensor and its pixels gather light, and the accuracy to which it determines the amount gathered by each pixel, are crucial in determining the quality of the recorded image. \cite{DSLRs} 

Hence, we need to have an accurate model for the CMOS Sensor. The noise effects in the CMOS Sensor have been separated out into the Noise Model; thus, this CMOS Model takes the input as the wavefront incident on the sensor due to the stars, and produces a no-noise matrix of pixel values as seen by the sensor. 

The processing sub-block involves the following steps -
\begin{enumerate}[label={}]
    \descitem{Trim to FOV -} This sub-sub-block trimming the database of all the stars to those within the Field of View of the Star Tracker, given its attitude. 
    \descitem{ICRS Frame to Lens Frame -} This sub-sub-block transforms the unit vectors of the stars in the database from the ICRS Frame to the Lens Frame (3D)
    \descitem{Lens Frame to Sensor Frame -} This sub-sub-block projects the 3D unit vectors of the stars onto the 2D Sensor Frame. 
    \descitem{Trim to Sensor -} This sub-sub-block trims the stars to within the Sensor Frame. This is because there can be stars within the Field of View, but still outside the Sensor Frame. 
    \descitem{Image Generation -} This sub-sub-block generates the image using the star database and the inputs. For more details, refer to \ref{subsubsection:IG}.
    \descitem{Noise Model -} This sub-sub-block adds the required noises at the Sensor.
\end{enumerate}

% ---------------- %
% Image Generation %
% ---------------- %

\subsubsection{Image Generation \label{subsubsection:IG}}

% ----------- %
% Noise Model %
% ----------- %


\subsubsection{Noise Model} % Introduction to noise model
The incoming light from the stars is the signal we need the CMOS Imaging Sensor to transcribe faithfully; inaccuracies in the recording process constitute noise, and inhibit the ability to reconstruct the Star Vectors in the image frame, which leads to inaccuracies in the Star Tracking and Star Matching Algorithms. In order to extract the best performance from the CMOS Imaging Sensor, it is helpful to have an understanding of the various contributions to image noise and how various design choices in the Lens System and the choice of CMOS Sensor affect this noise.

A flowchart for the Noise Model is as follows -

\begin{Flowchart}[h!]
    \centering
    \includegraphics[scale=0.09]{Figures/Model/Noise Model.png}
    \caption{Noise Model - Version 2}
    \label{fig:SIS_v2_NM}
\end{Flowchart}

There are several image sensor noise sources that must be simulated in the camera model. Our image sensor of choice is a CMOS sensor, and so, we have focused on the noises specific to a CMOS Sensor. The noises that have been considered in the Sensor Model, in a chronological order are - \emph{Parasitic Light Sensitivity, Photon Shot Noise, Photo-Response Non-Uniformity, Dark Noise, Fixed Pattern Noise, Read Noise,} and \emph{Pixel Storage Node Leakage}.

The order is based on the following information - 
The photons have dual nature, due to which, their detection at the CMOS Sensor follows Poisson Distribution, captured by the Photon Shot Noise. This noise is from before the photons even strike the Sensor, and is dependent on the inputs. We have 2 more noises that are dependent on the inputs - Parasitic Light Sensitivity, and the PRNU, so they are taken in the beginning. Dark Noise, Fixed Pattern Noise, Read Noise are independent of the input. Also, Pixel Storage Node Leakage needs to go to the last, because It is the number of pixels that leak out of the Storage Node.

% --- %
% PLS %
% --- %

\subsubsection{Parasitic Light Sensitivity} % ???
Parasitic Light Sensitivity (PLS) is the ratio of the light sensitivity of the photodiode to the light sensitivity of the Memory Node (also called the Storage Node) in Global Shutter. \newline

Parasitic Light Sensitivity Noise (PLSN) is due to the light incident into Memory Node. An increase of PLS leads to a deterioration in the image quality.  This  is  because  the  photo-electrons  generated  by  incident  light  to  Memory Node  are  added  to  the  photo-electrons stored in Memory Node after the exposure. \newline

The Memory Node is about 80,000x more sensitive than the Photodiode. However, the Memory Node is susceptible to photons only after the Shutter closes. So, the time to be taken into account is $(t_{Readout} - t_{Close})$. \newline

Formula Used in the code:
\begin{equation}
    \begin{aligned}
        \boxed{ \color{blue} PV =  PV_0 + \frac{PV_0}{\texttt{PLS}} \cdot \left(\frac{t_{Readout} - t_{Close}}{t_{Capture}}\right) \color{black}} 
    \end{aligned}
\end{equation}
where, $PV_0$ is the Pixel Value before \texttt{PLS} is applied. 

Derivation:
\begin{equation*}
    \begin{aligned}
        P_0 - \text{\# photons in } t_{Capture} & \rightarrow P_0 \\
        P - \text{ \# photons in } (t_{Readout} - t_{Close}) & \rightarrow P_0 \cdot \left(\frac{t_{Readout} - t_{Close}}{t_{Capture}}\right) \\
        \text{PV due to } P_0 \text{ in } t_{Capture} & \rightarrow PV_0 \\
        \text{PV due to } P \text{ in } (t_{Readout} - t_{Close}) & \rightarrow \frac{PV_0}{PLS} \cdot \left(\frac{t_{Readout} - t_{Close}}{t_{Capture}}\right)
    \end{aligned}
\end{equation*}
where, $PV$ is the Pixel Value. 

Note that the PLS Noise depends on the input illumination on the Sensor.

% --- %
% PSN %
% --- %

\subsubsection{Photon Shot Noise} % 3.
Image sensors measure scene irradiance by counting the number of discrete photons incident on the sensor over a given time interval. The independence of random individual photon arrivals leads to photon noise, a signal dependent form of uncertainty that is a property of the underlying signal itself. Individual photon detections can be treated as independent events that follow a random temporal distribution. As a result, photon counting is a classic Poisson process. Even from Quantum Statistics, when collecting photons from an unvarying source over a set amount of time, we get a Poisson Distribution. Hence, if the mean value of the number of photons that hit the sensor is $n$, the variance in the number of photons is the $\sqrt{n}$. This is captured by the MATLAB function \texttt{poissrnd}.

The formula used in the code is:
\begin{equation}
    \boxed{ \color{blue} PV = \texttt{poissrnd}(PV_0) \color{black}}
\end{equation}

% ---- %
% PRNU %
% ---- %

\subsubsection{Photo-Response Non-Uniformity} % 4.
When uniform light falls on a camera sensor, each pixel should output exactly the same value. However, small variations in cell size and substrate material result in slightly different output values. The difference between the true response from a sensor and a uniform response is known as \emph{Photo Response Non Uniformity} (PRNU).

Since PRNU is caused by the physical properties of the sensor itself, it is almost impossible to eliminate completely and is usually considered to be a normal characteristic of the sensor. It is a light sensitive noise and hence, signal-dependent.

PRNU in \% of Signal is the non-uniformity in spatial variation of pixel value for specific illumination.

The formula used in the code is:
\begin{equation}
    \boxed{ \color{blue} PV = PV_0 + \mathcal{N}(\texttt{PRNU} \cdot PV_0, \texttt{PRNU} \cdot PV_0)   \color{black}}
\end{equation}

where, $PV$ is the new Pixel Value, $PV_0$ is the old Pixel Value, \texttt{PRNU} is the PRNU Noise value in \%, and $\mathcal{N}(\mu, \sigma)$ is the Normal Distribution Function.

A Pseudo-Random Generator with a Seed Value is used to ensure that the noise remains same across iterations because \texttt{PRNU} Value is remains same for each pixel over time. 

% -- %
% DN %
% -- %

\subsubsection{Dark Noise} % 6. Dark Current, DSNU, Dark Noise
Dark Noise, given in no. of Electrons, is the noise due the reverse bias leakage current in all diodes. The average dark signal delivered by a sensor or a camera will be composed out of - a fixed DC offset, very often introduced by the analog circuitry on pixel/column/chip-level, or by an
extra black level offset, and a thermal component, also known as the dark current or leakage current. This part has a linear dependency on the exposure or integration time as well as temperature (at least if saturation of the sensor is not reached). The dark current decreases with decreasing temperature.

The Dark Temporal Noise is given in number of electrons and the Dark Signal / Dark Current is given in number of electrons per second. The variance of the Dark Noise is given as $DS \cdot t_S$.

As the dark current results from spontaneously generated electrons, the dark current is measured by simply "counting" these electrons. Since counting electrons obeys Poisson statistics, the noise associated with the dark current I is proportional to the square root of the number of dark electrons that accumulate during the exposure. 

Formula Used In the code:  
\begin{equation}
    \boxed{ \color{blue} PV = PV_0 + \texttt{G} \cdot \texttt{round}(\mathcal{N}(\texttt{DTN} + \texttt{DS} \cdot t_S, \sqrt{\texttt{DS} \cdot t_S}))   \color{black}}
\end{equation}

where, $G$ is the Gain, $PV$ is the new Pixel Value, $PV_0$ is the old Pixel Value, \texttt{DTN} is the Dark Temporal Noise value in \# $e^-$, \texttt{DS} is the Dark Signal in \# $e^-/s$, $t_S$ is the exposure time and $\mathcal{N}(\mu, \sigma)$ is the Normal Distribution Function.

Note that the rounding is important as number of electrons can't be a fractional number. 

% --- %
% FPN %
% --- %

\subsubsection{Fixed Pattern Noise} % 5.
FPN (also called non-uniformity) in LSB10 is the spatial percentage variation in pixel output values under uniform illumination due to device and interconnect parameter variations (mismatches) across the sensor. It is fixed for a given sensor, but can vary from sensor to sensor.This is the standard deviation value.

Fixed Pattern Noise is the variation in pixel dark signal over a frame and is determined by calculating Standard Deviation of mean image obtained from set of frame taken in dark.

Fixed Pixel Noise in LSB10 is the non-uniformity in spatial \% variation of
Pixel Values, independent of Specific Illumination.

This is the standard deviation value.

The formula used in the code is:
\begin{equation}
    \boxed{ \color{blue} PV = PV_0 + \mathcal{N}(0, \texttt{FPN})   \color{black}}
\end{equation}

where, $G$ is the Gain, $PV$ is the new Pixel Value, $PV_0$ is the old Pixel Value, \texttt{FPN} is the FPN noise value in LSB10, and $\mathcal{N}(\mu, \sigma)$ is the Normal Distribution Function.

A Pseudo-Random Generator with a Seed Value is used to ensure that the noise remains same across iterations because FPN Value is remains same for each pixel over time.

% -- %
% RN %
% -- %

\subsubsection{Read Noise} % 9.
Read noise is a combination of noise from the pixel and from the ADC. The Read Noise (RN) of the sensor is the equivalent noise level (in electrons RMS) at the output of the camera in the dark and at zero integration time. The ADCs for a CMOS image sensor are present for each pixel.

Read noise basically determines the contrast resolution that the camera is able to achieve. The lower the read noise level, the lower the minimum number of signal electrons that can be detected. Read noise is also important in combination with expressing the sensitivity of a camera. 

It is one of the main sources of noise in an imaging camera for relatively short exposures. Low read noise is desirable as it allows the camera to detect low level signals and attain a high dynamic range and therefore results in a more sensitive sensor.

The read noise of the CMOS sensor is a noise distribution and is normally given as in $e^-$, as a median value.

Formula used in the code:
\begin{equation}
    \boxed{ \color{blue} \texttt{DNR} = 20 \cdot \log_{10} \left(\frac{\texttt{FWC}}{\texttt{Read Noise}} \right) \color{black} }
\end{equation}

where, \texttt{DNR} is the Dynamic Range of the Pixel, \texttt{FWC} is the Full Well Count. 

Note that the Read Noise is an almost constant value.

% ---- %
% PSNL %
% ---- %

\subsubsection{Pixel Storage Node Leakage} % 7. 

In a global shutter, after exposure the integrated charge from each pixel is transferred to the pixel storage node. Since this is typically diffusion, it has some leakage. The storage nodes of some pixels are leakier than others, resulting in the bright spots that can be seen in images with larger frame times and the default timing.

The storage node of each row is reset during the row overhead time of the previous frame. The time between 2 resets of the floating diffusion is therefore equal to $\frac{1}{frame rate}$.

Formula Used in the code:
\begin{equation}
    \boxed{ \color{blue} PV = PV_0 - \texttt{G} \cdot \texttt{round}(\texttt{PSNL} \cdot (t_{Readout} - t_{Close}) \color{black}}
\end{equation}

where, $G$ is the Gain, $PV$ is the new Pixel Value, $PV_0$ is the old Pixel Value, \texttt{PSNL} is the PSNL noise value in \# electrons.
 
% ------------- %
% Sample Images %
% ------------- %
 
\subsubsection{Sample Images}
These are some images generated using the \SISM Version 2 in Figure \ref{fig:sample_images}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_1.png}
        \caption{Sample Image 1}
        \label{fig:sample_1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_2.png}
        \caption{Sample Image 2}
        \label{fig:sample_2}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_3.png}
        \caption{Sample Image 3}
        \label{fig:sample_3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_4.png}
         \caption{Sample Image 4}
         \label{fig:sample_4}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_5.png}
        \caption{Sample Image 5}
        \label{fig:sample_5}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/Model/Sample Images/Image_6.png}
         \caption{Sample Image 6}
         \label{fig:sample_6}
    \end{subfigure}
    \caption{Sample Images}
    \label{fig:sample_images}
\end{figure}
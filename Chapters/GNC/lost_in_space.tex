\documentclass[../../main.tex]{subfiles}

%-----------------------------------------------------------%
\begin{document}
\section{Star-Matching}

\subsection{Introduction}

The goal of Star-Matching is to match the stars identified in an image to its corresponding star from the Star-Catalogue. This process of \textit{"tagging"} an image star with the Star-ID of its catalogue counterpart is the most complicated task for
any algorithm, and different algorithms can be distinguished mainly by how well they accomplish this task. 
If no match is found for an image star, it is tagged as a false star. Certain Star-Matching algorithms also provide for a verification step, which can rule out false matches that might have occurred at the end of the Star-Matching process.

Generally the matching is done by comparing the Star-Catalogue information to stars detected in the image. Despite the fact that catalogues also include brightness intensity as well as location information of stars, brightness is rarely used as filter in the process of Star-Matching. It has been shown that the probability of correct star matches is significantly influenced by the errors in estimation of star brightness, when brightness-based algorithms are used \cite{accardo2002brightness}.
Since the catalogues store visual magnitude of stars, whereas the brightness of the stars on an image is sensitive to the instruments, the process of predicting the image star's brightness from the catalogue star's brightness value is not a trivial process. In addition to this, brightness values are also considerably affected by noise and sensor malfunctions.

A Star-Matching algorithm, needs to match a minimum of two stars from an image to its respective catalogue star in order for the estimation algorithm to estimate the attitude. 
Matching more image stars, leads to an increased accuracy in the attitude estimate. Hence, for a given Star Tracker, a certain number of stars have to be matched in every image in order for the attitude to be accurate. This number is a fixed threshold ($N_{TH}$) for the system.

Star-Matching algorithms are of two distinct types, which arises from the two distinct modes in which a Star Tracker operates.
When it is first activated, a Star Tracker has no information about the satellite’s orientation (\textit{attitude}). This is known as the \textbf{Lost-in-Space (LIS) mode}. However, once the initial attitude has been found, it enters into the \textbf{Tracking mode}, which aids the algorithm in
estimating the attitude in the subsequent images. This involves predicting the current attitude accurately from
previously obtained information (the previous attitude and the angular velocity rates).


\subsection{Lost-in-Space}
\subsubsection{Introduction}

As mentioned earlier, a Star Tracker operates in the Lost-in-Space mode when it has no \textit{a priori} information of the attitude. Such cases occur when the STADS module is turned on for the first time, or when the Tracking mode fails.

A literature survey was performed to select a suitable algorithm for the Lost-in-Space mode. A few algorithms stood out in particular over the course of the survey. These algorithms, or a variant of the said, appeared to be used commonly, either due to their relatively simple implementation, their efficient and shorter run-time process, and their robustness to noise and non-star objects that could enter the FOV.
Some of these algorithms are mentioned in detail.

\subsubsection{Planar Triangle Star Identification Technique}

This algorithm \cite{mcbryde2012star} analyzes the triangles formed by three stars at a time, matching the patterns using characteristics of the triangle. These characteristics include the area and polar moment of the triangle calculated using Herons’s formula. 
Then using a search method such as the \textbf{k-vector} (\textit{a search-less method}) \cite{mortari2014k}, all the triangles whose characteristics lie within one standard deviation of the observed triangle's are found. 
If more than one catalogue triangle meets the area and polar moment criteria, another star from the image is selected to identify and see how many stars overlap the two lists. If only two stars overlap then the triangle is identified. Else the solution is discarded and the algorithm works on a new star triangle formed by the image stars. 
Once three stars have been identified, the remaining stars in the image can be identified using a pivoting process. 

In their testing of the algorithm, out of 200 runs, it returned a false positive twice. This algorithm was implemented on hardware as well. 
However, this was one of the earliest Star-Matching methods that was developed. More robust and faster implementations have since been developed, and thus this algorithms was not considered.

\subsubsection{Shortest Distance Transform Technique}

This algorithm \cite{delabie2013highly} generates images using the star catalogue with a window that is slightly bigger than the FOV. These images are generated in such a way so as to cover the entire celestial sphere - Fig \ref{fig:sphere}. 
The generation of images requires one to distribute points on a sphere that is equidistant, and separated by the FOV angles.

\begin{figure}[h]
    \centering
    \includegraphics[scale = 0.25]{Figures/GNC/shortest_dist_sphere.png}
    \caption{Equidistant points on a sphere}
    \label{fig:sphere}
\end{figure}
Once these images are generated for the entire celestial sphere, the image from the sensor is taken.

The image from the sensor is compared with respect to all of the generated images. Two methods can be employed to compare the images:

\begin{itemize}
    \item \textbf{Two-Brightest-Stars Method}
    
    \begin{figure}[h!]
        \centering
        \includegraphics[scale=0.35]{Figures/GNC/shortest_dist_2_brightest.PNG}
        \caption{Shortest Distance Transform Technique: Two-brightest-stars Method}
    \end{figure}
    
    The brightest star from the generated image is placed in the same position as the brightest star from the captured image, thereby solving the translation problem. 
    Following which, the second brightest star from the captured image is rotated toward the second brightest star of the generated image. This is called the rotation step which ends up matching the images.
    
    \item \textbf{Centroid Method}
    
    \begin{figure}[h!]
        \centering
        \includegraphics[scale=0.35]{Figures/GNC/shortest_dist_centroid.PNG}
        \caption{Shortest Distance Transform Technique: Centroid Method}
    \end{figure}
    
    This method uses the individual centroids of the $N$ brightest stars as well as the center of these centroids, obtained from the captured image to solve for the translation problem. 
    Vectors between the center to the individual centroids of the stars are calculated. These vectors are then rotated, so that they vectors from the captured image aligns with that of the vectors from the generated image. This procedure results in the matching of the centre and roll angle of the images.
\end{itemize}

In their testing, the computational time of the algorithm with the centroid method was one-third lower when the six brightest stars were used. The execution time of the algorithm was said to increase linearly with the number of pixels.
An important point to be noted here is that the algorithm is capable of accurately determining whether the offered solution is the correct one.
This algorithm could support both the LIS and Tracking mode, besides having been extensively tested with a variety of distortions in the captured image.

This algorithm was initially considered, when we intended on using the \textit{Attitude estimation using image matching technique} (refer \ref{sec:AIM}), which required a corresponding star-matching  algorithm that worked directly on the image coordinates and not the unit-vectors for faster computational performance. 

However, when QUEST was finalized as the estimation algorithm for the system, which implied the constraints of AIM no longer applied. Thus it was decided to proceed with a Star-Matching algorithm that had been tested and implemented on actual hardware, or actual space-based missions.


\subsubsection{Radial and Cyclic Star Matching Technique}

This algorithm \cite{zhang2008full} requires the centroids to be in polar coordinates $(r, \theta)$ instead of Cartesian $(x, y)$ coordinates.

\begin{itemize}
    \item \textbf{Radial Matching}
    
    \begin{figure}[!h]
        \centering
        \includegraphics[scale=0.35]{Figures/GNC/radial_technique.PNG}
        \caption{Radial Matching Technique}
        \label{fig:radial}
    \end{figure}
    
    A reference star $S$, is chosen and all the other stars in the image are called neighbour stars - $(T_i)$ of $S$, by considering the reference star $S$ as the centre. Following which the area surrounding $S$ is divided into $N_q$ uniformly spaced strips, where each strip represents an angular distance of $R_r/N_q$. $R_r$ here is the maximum radial pattern radius. 
    
    An array of size $N_q$ is generated with all the elements initialized to $0$. If a star exists in the $i^{th}$ strip, then the $i^{th}$ element of the array becomes $1$. Thus this array represents the radial pattern of the reference star - $S$ - $pat_r (S)$.
    
    \item \textbf{Cyclic Matching}
    
    \begin{figure}[!h]
        \centering
        \includegraphics[scale=0.35]{Figures/GNC/cyclic_technique.PNG}
        \caption{Cyclic Matching Technique}
        \label{fig:cyclic}
    \end{figure}
    
    Using a similar reference star and neighbouring star technique, with the reference star $S$ being set as the centre and a suitable cyclic pattern radius of $R_c$, the central angles between neighbour stars are calculated, i.e, $\angle T_i S T_j$ ,$\forall$ $i\neq j$. The smallest angle $\angle T_l S T_k$ is selected and the side $ST_l$ is made the starting side. The image is then evenly partitioned into $8$ sectors. 
    
    An array of length $8$, similar to the radial pattern of $S$ is generated. If a star is found in the $i^{th}$ sector, then the $i^{th}$ place of the array becomes $1$.

\end{itemize}

The radial pattern and cyclic pattern arrays are used as a reference and searched upon in the processed catalogue to find stars that have similar pattern arrays. Thus it is required to have generated such pattern arrays for all the stars of the catalogue. This data is stored in the form of a lookup table for faster access.

In its testing through simulations, the star identification rate increases with increasing $R_r$, and an appropriate $N_q$ needs to be selected.

This method was initially considered since its FPGA-based implementation \cite{zhao2017real} claimed to be faster than the traditional implementations of Star-Matching algorithms on a micro-controller. However, with the increasing complexities involved in the FPGA programming of this algorithm, lead to the decision to disqualify this algorithm.


\subsubsection{Geometric Voting Algorithm}
\label{sec:GVA}
This method \cite{kolomenkin2008geometric} requires all the close-pairs of catalogue stars to be sorted in a lookup table based on the distances between the stars.

The angular distance between every pair of stars from the captured image is calculated, and its corresponding catalogue star pair is found from the lookup table. These catalogue star pairs then vote for the image star pair with similar distances. As the angular distance is a symmetric relationship, each member of the catalogue star pair votes for each member of the image star pair. 
Each vote here corresponds to a possible identity for the image star, from the respective catalogue star. Usually, the correct identity of an image star is the one that receives the most number of votes at the end of process. Since this approach relies only on geometric information, it is thus not sensitive to the photometric properties of the sensor which might change during the operation of the system.
The use of star brightness as a filter was left for further studies, with the capability to reduce the runtime of the algorithm.

This algorithm (\ref{fig:GVM_runtime}) uses information from the entire image and does not rely only on the local neighbourhoods of a certain star, thus making it more robust. The voting method is also capable of ignoring non-star objects in the image since the concurrent use of all of the image stars minimizes the influence of these non-stars.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{Figures/GNC/GVM_Runtime.PNG}
    \caption{Geometric Voting Algorithm - Runtime Pseudo-code}
    \label{fig:GVM_runtime}
\end{figure}


An important aspect of this algorithm, is that there is a verification step (\ref{fig:GVM_verification}) after right after the voting step. 
If a non-star object is ever detected by Feature Extraction, there is a reasonable probability of the non-star being voted on by an actual catalogue star. It can thus be misidentified as a star. Such \textbf{false matches} affect the accuracy when calculating the attitude, and hence should be minimized. Hence a verification step, that can accurately detect and ignore such star-pairs is important for 

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{Figures/GNC/GVM_Voting_Method.PNG}
    \caption{Geometric Voting Algorithm - Verification Step Pseudo-code}
    \label{fig:GVM_verification}
\end{figure}

This algorithm was initially considered, and was implemented in Python.
One of the key issues, however, was the \textit{localization uncertainty} ($\delta$), an important parameter in deciding the interval of the search window for a given angular distance. 
The parameter can be interpreted as the noise that arises from detection of stars by the sensor, as well as the noise involved in Feature Extraction. Thus, this parameter could not be theoretically calculated, but had to be tuned either by running simulations, or testing out the algorithm on actual hardware.

It was, however, decided to disqualify this algorithm, because of the following concerns:
\begin{enumerate}
    \item Ambiguity in how to proceed if a star receives equal number of votes from two or more catalogue stars
    
    \item The minimum number of votes that an image star should accumulate for the matching to occur was ambiguous
    
    \item The verification step did not mention the minimum number of votes that a star should accumulate for it to pass the step
    
    \item The time-taken to search for the angular distance of an image star pair from the lookup table was time-consuming, since the lookup table was large, and the average number of stars in an image was large as well 
\end{enumerate}

The 4-Star Matching Algorithm (Refer \ref{sec:4SM}), addressed these issues, and was thus selected as the Lost-in-Space algorithm.


\subsubsection{4-Star Matching Algorithm}
\label{sec:4SM}

This algorithm \cite{dong2006brightness} involves a “4-star matching” pattern recognition procedure, that requires a  brightness independent guide star catalogue as well as a K-vector based reference star catalogue. The generation of these catalogues depends on parameters such as the Limiting Magnitude, and the FOV of the optics system.

The Limiting Magnitude for the optics systems was decided as 6. The number of stars from the star catalogue with a visible magnitude $\le 6$ are 5060 - these stars are classified as the \textbf{Guide Stars}. The catalogue that contains the Star-IDs of these stars, as well as the pointing unit vectors of these stars in the ICRS frame is stored as part of the \textbf{Guide Star Catalogue}.
The pairwise angular distance is computed between every pair of the Guide Stars as follows:
\begin{equation}
    d_{ij} := \cos(\theta_{ij}) = \vect{v_i}.\vect{v_j} = \vect{v_{ix}}\vect{v_{jx}} + \vect{v_{iy}}\vect{v_{jy}} + \vect{v_{iz}}\vect{v_{jz}}
    \label{eq:ST_AngDst}
\end{equation}
where, $\vect{v_i}$ corresponds to the pointing unit vector of the $i^{th}$ Guide Star.
If this computed angular distance is $\le$ the FOV ($cos(\phi)$, where $\phi=$ FOV), they are stored.
All such pairs of stars are then compiled, and are sorted based on their angular distance. These angular distance values are then used to generate the K-vector for the angular distance. These pairwise Star-IDs and the corresponding K-vector value is stored as part of the \textbf{Reference Star Catalogue} (\ref{appendix:star_catalogue}). These catalogues shall be available on-board the STADS module (\ref{tab: guide_star_catalogue}, \ref{tab: reference_star_catalogue})    .

 
When the module takes an image, the centroids of the stars that are identified from the image are obtained from Feature Extraction. These 2-dimensional centroids are then converted to 3-dimensional unit vectors (\ref{fig:pin_hole_camera_model}) in the body-frame that point towards the source of light responsible for a given centroid \textit{(using the pin-hole camera model)} \cite{erlank2013development}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.35]{Figures/GNC/pin_hole_camera_model.png}
    \caption{Pin Hole Camera Model}
    \label{fig:pin_hole_camera_model}
\end{figure}

For a given $(x, y)$ centroid the corresponding unit vector is defined as follows:
\begin{equation}
    \begin{bmatrix} u_{x} \\ u_{y} \\ u_{z} \end{bmatrix} = \begin{bmatrix} x/r_{2} \\ y/r_{2} \\ f/r_{2} \end{bmatrix}
\end{equation}
\begin{equation}
    r_{2} = \sqrt{x^2 + y^2 + f^2}
\end{equation}

where, $f = $ focal length of the optic system in the module.

Once these 3D unit vectors are generated for each of the centroids present in the image, the algorithm dictates that the Star-Matching process be operated on \textbf{four stars} at a time.

Once these four stars are selected, the pairwise angular distances between every possible star pair is computed using their corresponding unit vectors (\ref{eq:ST_AngDst}). Hence there are $\binom 4 2 = 6$ unique angular distances.
These angular distances are stored in an array called the \textbf{Star-Pair Array} (SPA), which is defined as follows:
\begin{equation}
    \text{SPA} = \begin{bmatrix}s_1\\ s_2\\ s_3\\ s_4\\ s_5\\ s_6\end{bmatrix} := \begin{bmatrix} d_{12} \\ d_{13} \\ d_{14} \\ d_{23} \\ d_{24} \\ d_{34} \end{bmatrix}
\end{equation}

where, $d_{ij}$ corresponds to the angular distance between the $i^{th}$ and $j^{th}$ image-star.

Now for a given element from the SPA, the algorithm needs to find all those star-pairs from the Reference Star Catalogue whose angular distance $(d_{ij})$ lies in the interval:
\begin{equation}
    d_{ij} \in [s_i-\delta, s_i+\delta]
    \label{eq:ST_SearchWindow}
\end{equation}
where, $\delta$ is the \textit{localization uncertainty} which was discussed before. However instead of searching through the entire Reference Star Catalogue to find all those entries which satisfy the condition given by (\ref{eq:ST_SearchWindow}), the algorithm employs the use of K-vector to perform this task \textit{`search-lessly'}.

Firstly the following values are computed:
\begin{equation}
    k_{bot} = \text{floor}\bigg[ \frac{\big(\cos(\delta)s_i - \sin(\delta)\sqrt{1 - s^2_i} \big)- q}{m} \bigg]
\end{equation}
\begin{equation}
    k_{top} = \text{ceil}\bigg[ \frac{\big(\cos(\delta)s_i + \sin(\delta)\sqrt{1 - s^2_i} \big)- q}{m} \bigg]
\end{equation}
where, $q=$ the y-intercept of the Z-vector line , and $m=$ slope of the Z-vector line (Ref \ref{appendix:k-vector}).

The ID range of candidate star-pairs is then obtained from the K-vector as follows:
\begin{equation}
    R_{start} = K[k_{bot}] + 1
\end{equation}
\begin{equation}
    R_{end} = K[k_{top}]
\end{equation}
where, K[i] refers to the $i^{th}$ element of the K-vector, $R_{start}$ refers to the start index of the Reference Star Catalogue, and $R_{end}$ refers to the end index of the Reference Star Catalogue.

All those star-pairs that $\in [R_{start}, R_{end}]$ are termed as candidate star-pairs. The Star-IDs of these candidate star-pairs are stored in an array called the \textbf{Candidate Star-Pair Array} (CSPA). Note that the size of this array is cannot be fixed before, but rather be dynamically allotted since the number of the candidate star-pairs vary for each measured angular distance.

A \textbf{Star Identification Matrix} (SIM) is then constructed with the dimensions - $(N, 6)$ where $N = $ number of Guide Stars, and all the elements are initialized to zero. 
Subsequently the CSPA for the first element in the SPA is computed. All those rows of the SIM corresponding to the Star-IDs stored in CSPA are selected. The first column of all these rows are then updated to 1.
Similarly, the algorithm proceeds with the rest of the SPA elements, updating the $i^{th}$ column values respectively for the $i^{th}$ SPA element.

If and only if there is \textbf{one row} from the SIM that is exactly $[1,1,1,0,0,0]$, the index of this row is identified as the Catalogue Star-ID of the first image-star.
If there are no rows or more than one row with this value, then the first image-star cannot be identified. Similarly, for the other stars, the rows need to be as follows:
\begin{equation}
    \begin{bmatrix} S_1 \\ S_2 \\ S_3 \\ S_4\end{bmatrix} = \begin{Bmatrix} [1,1,1,0,0,0] \\ [1,0,0,1,1,0] \\ [0,1,0,1,0,1] \\ [0,0,1,0,1,1] \end{Bmatrix}
\end{equation}

Once an image-star is matched, it is not used again. The remaining image-stars are used with additional image-stars to make a new 4-star group. The above procedure is then repeated.
If none of the four stars are identified in a matching procedure, at least one star should still be removed to build a new 4-star group. In this way all of the image-stars are matched.

This algorithm was selected as the Star-Matching algorithm for the Lost-in-Space mode, because:
\begin{enumerate}
    \item The paper which had laid down the 4-Star Matching Algorithm \cite{dong2006brightness}, had done so without any ambiguity in its implementation, and was thus a straightforward task to implement it
    \item The algorithm employed the K-vector based \textit{search-less} technique which would significantly reduce the run-time of Star-Matching
\end{enumerate}

\textbf{Verification Step}

At the end of any Star-Matching algorithm, as mentioned earlier in (\ref{sec:GVA}), it is important to have a verification step that can detect \textbf{false matches} if any, and hence discard them from being used by the estimation algorithm to estimate the attitude.

The verification step that was implemented in the Geometric Voting Algorithm \cite{kolomenkin2008geometric} was used as reference. This step, however, was modified before being implemented.
% insert flowchart

The voting strategy is employed, to vote all the matched image-stars whose pairwise angular distance with other matched image-stars computed using the body-frame vectors $(d_{ij})$ equals \textit{(to a predetermined tolerance)} the angular distance computed using the ICRS-frame vectors of the respective matched Guide Stars $(d'_{ij})$, defined as follows:
\begin{equation}
    \bigg|\frac{d_{ij}}{d'_{ij}} - 1\bigg| \le \frac{tol}{100}
    \label{eq:ST_Verify_Tol}
\end{equation}
where, $tol=$ the tolerance value, expressed in percentage. In this case a value of $tol=2\%$ was chosen.
It can be observed that the maximum number of votes which can be accumulated by an image-star is $(N-1)$, where, $N=$ the number of matched image-stars. However, if there any false matches, this maximum value will not be accumulated by any of the image-stars. Hence the following checks were enforced to detect these false matches.

Once the voting step is completed for all the matched image-stars, the votes accumulated are checked against a lower-bound which is computed as follows:
\begin{equation}
    n_{LB} = \frac{p_1 \times N}{100}
\end{equation}
where, $p_1=$ the lower-bound, expressed in percentage. In this case a value of $p_1=35\%$ was chosen. 
All those image-stars which have votes $\le n_{LB}$, are considered to have \textbf{failed}, and hence discarded. Let this number of failed stars be $N_f$.
This constitutes the \textbf{Check-1} step.

Following this, a threshold value is calculated as follows:
\begin{equation}
    n_{TH} = \frac{p_2 \times (N - N_f)}{100}
\end{equation}
where, $p_2=$ the threshold, expressed in percentage. In this case a value of $p_2=80\%$ was chosen. All those image-stars which have votes $\ge n_{TH}$ are considered to have \textbf{passed}, and thus matched properly. 
Only these image-stars are considered by the estimation algorithm to estimate the attitude.
This constitutes the \textbf{Check-2} step.

The Check-1 step, ensures that all those image-stars which have accumulated too few votes are appropriately removed. 
An assumption is made here, which is that these image-stars that are removed were indeed \textbf{false matches} because of the low number of votes.
Hence any of the other image-star should have accumulated the maximum of $(N-N_f-1)$ number of votes, provided they are all true matches. 
However, it is not necessary that from the remaining pool, all the stars be true-matches, and thus accumulate $(N-N_f-1)$ number of votes.

Hence to remove \textbf{probable false matches} from the remaining pool of image-stars, Check-2 step is included.
From the earlier assumption, it can be deduced that the falsely matched image-stars, in the initial voting stage, would have had no impact in the voting step of other stars, since the angular distances computed using these falsely matched image-stars and other matched image-stars would fail the condition given by (\ref{eq:ST_Verify_Tol}). \\
Hence the threshold value $n_{TH}$ which is computed, appropriately signifies the minimum number of votes that should be accumulated by an image-star from the remaining pool for it to be a true match.

\textbf{Concerns}

The 4-Star Matching Algorithm was tested against the images generated by the Star Image Simulation Model (\ref{sec:SISM}). These images spanned only a small section of the celestial sphere. However, even these images revealed the following concerns:
\begin{enumerate}
    \item There are certain binary star-systems, which are too close to be resolved by the current optics system, and thus will be detected as a single star (this was observed in the images generated by the Star Image Simulation Model). Hence such stars were falsely matched. \\
    One solution to overcome such cases would be to manually classify such close binary stars as a \textit{single pseudo-star} in the Guide Star catalogue as well as the Reference Star Catalogue.
    
    \item There were cases when certain non-binary stars were falsely matched. The reason behind such matches needs to be looked into.
    
    \item The current algorithm was written and tested on MATLAB. However, to actually estimate  the run-time of Star-Matching, it needs to be tested on the appropriate hardware. This can also reveal other concerns with the algorithm, which cannot be detected on MATLAB.
\end{enumerate}

\textbf{Future Work}

The 4-Star Matching Algorithm needs to be thoroughly tested with generated images that span the entire celestial sphere, so as identify any other issues/concerns with the algorithm.

Currently the Guide Star Catalogue that is generated using a Limiting Magnitude of 6 consists of 5060 stars. The Reference Star Catalogue that is generated using the dimensions of the Field-of-View, consists of 188700 star-pairs. 
Based on the hardware capabilities of the system, it is not yet certain, whether these large catalogues can be accommodated on-board the module.

Hence, a reduction in the number of Guide Stars in the Guide Star Catalogue is left for future work, based on the system requirements, which would therefore imply a reduction in the Reference Star catalogue as well.
This reduction in the Guide Stars, has to be carried out in such a way so as to meaningfully reduce the catalogue sizes, while ensuring that the accuracy, or robustness of the Star-Matching algorithm is preserved, or suffers only a fractional reduction. The trade-offs between the accuracy of the algorithm and the reduction in catalogue size will then have to be analysed, before this task is taken up.
If the reduction is indeed required, then the work done by Li, et. al. \cite{li2014new} will be considered and taken as reference to complete this task.

%----------------------------END----------------------------%
\end{document}